{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-19T21:38:05.643267Z",
     "start_time": "2026-02-19T21:38:05.423430Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:38:14.670241Z",
     "start_time": "2026-02-19T21:38:09.206693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from utils import *\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_1samp\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ],
   "id": "cb10e655aa283cfd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:38:15.090877Z",
     "start_time": "2026-02-19T21:38:14.676221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "names = {'vertex_ai/gemini-2.0-flash': 'Gemini 2.0 Flash', \n",
    "         'azure/gpt-4o': 'GPT-4o',\n",
    "         'azure/gpt-4o-mini': 'GPT-4o Mini',\n",
    "         'ollama_chat/llama3.1:8b-instruct-fp16': 'Llama 3.1 8B Instruct',\n",
    "         'ollama_chat/mistral:7b-instruct': 'Mistral-v0.3 7B Instruct',\n",
    "         }\n",
    "\n",
    "names = {model_name_clean(k): v for k, v in names.items()}\n",
    "names.update({'all': 'All'})"
   ],
   "id": "94b425bb2077291b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:38:18.720715Z",
     "start_time": "2026-02-19T21:38:17.914931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs('plots', exist_ok=True)\n",
    "os.makedirs('plots/png', exist_ok=True)\n",
    "os.makedirs('plots/pdf', exist_ok=True)\n",
    "os.makedirs(f'results/choice_analysis_details', exist_ok=True)\n",
    "\n",
    "results_dir = 'results/merged'"
   ],
   "id": "3985646dc5ca6d4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:38:22.327635Z",
     "start_time": "2026-02-19T21:38:22.018653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_first_choice(choice_list):\n",
    "    if isinstance(choice_list, str):\n",
    "        choices = eval(choice_list)\n",
    "    elif isinstance(choice_list, list):\n",
    "        choices = choice_list\n",
    "    else:\n",
    "        return np.nan\n",
    "    for i in range(len(choices)):\n",
    "        x = choices[i]\n",
    "        if not isinstance(x, int):\n",
    "            continue\n",
    "        else:\n",
    "            return x - 1\n",
    "    return np.nan       "
   ],
   "id": "14c438a871ce61b1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:41:35.161665Z",
     "start_time": "2026-02-19T21:39:51.490180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_results = []\n",
    "all_diffs = []\n",
    "all_choices = []\n",
    "for model in names.keys():\n",
    "    if model == 'all':\n",
    "        continue\n",
    "    for manipulation in ['none', 'punish', 'money', 'demotivate-futility']:\n",
    "        print(f'Model: {model}, Manipulation: {manipulation}')\n",
    "        df = pd.read_csv(os.path.join(results_dir, f'{model}.csv'))\n",
    "        numeric_cols = [col for col in df.columns \n",
    "                if 'answer' not in col \n",
    "                if 'execute' not in col\n",
    "                and col not in ['sub_task_id', 'task_id', 'category', 'task', 'sub_task', 'response',\n",
    "       'prompt', 'success', 'error']]\n",
    "        df = df.dropna(subset=numeric_cols)\n",
    "        df = agg_remove_nans(df, numeric_cols)\n",
    "        \n",
    "        # load choice data\n",
    "        df_choice = pd.read_csv(os.path.join('results', 'pre_choose', f'{model}--{manipulation}.csv'))\n",
    "        if manipulation == 'none':\n",
    "            # in the \"none\" condition, we didn't have the \"manipulate_on\" column, so we need to load it from the \"money\" condition\n",
    "            df_choice_2 = pd.read_csv(os.path.join('results', 'pre_choose', f'{model}--money.csv'))\n",
    "            assert df_choice['sub_task_id_0'].equals(df_choice_2['sub_task_id_0'])\n",
    "            df_choice['manipulate_on'] = df_choice_2['manipulate_on']\n",
    "        df_choice = df_choice[['sub_task_id_0', 'sub_task_id_1', 'task_number', 'manipulate_on']].rename(columns={'task_number': f'choice--{manipulation}'})\n",
    "        \n",
    "        # clean choice data\n",
    "        df_choice = df_choice.dropna(subset=[f'choice--{manipulation}'])\n",
    "        df_choice[f'first_choice--{manipulation}'] = df_choice[f'choice--{manipulation}'].apply(extract_first_choice)\n",
    "        df_choice = agg_remove_nans(df_choice, [f'choice--{manipulation}'])\n",
    "        \n",
    "        # merge choice data with the main data (i.e., the motivation scores) \n",
    "        # to get the motivation scores for both tasks in each choice pair, according to the manipulation condition.\n",
    "        # the manipulation is applied on either task 0 or task 1, depending on the \"manipulate_on\" column.\n",
    "        if manipulation == 'none':\n",
    "            cols = [f'{method}--{model}--none' for method in ['motivation_score']]\n",
    "            df_choice = pd.merge(left=df_choice, right=df[['sub_task_id', *cols]], left_on='sub_task_id_0', right_on='sub_task_id', how='inner')\n",
    "            df_choice = df_choice.drop(columns='sub_task_id')\n",
    "            df_choice = df_choice.rename(columns={c: f'{c.split(\"--\")[0]}_0' for c in cols})\n",
    "            df_choice = pd.merge(left=df_choice, right=df[['sub_task_id', *cols]], left_on='sub_task_id_1', right_on='sub_task_id', how='inner')\n",
    "            df_choice = df_choice.rename(columns={c: f'{c.split(\"--\")[0]}_1' for c in cols})\n",
    "        else:\n",
    "            cols_none = [f'{method}--{model}--none' for method in ['motivation_score']]\n",
    "            cols_manip = [f'{method}--{model}--{manipulation}' for method in ['motivation_score']]\n",
    "            \n",
    "            df_choice_1 = pd.merge(left=df_choice[df_choice['manipulate_on'] == 0], \n",
    "                                   right=df[['sub_task_id', *cols_manip]], \n",
    "                                   left_on='sub_task_id_0', \n",
    "                                   right_on='sub_task_id', \n",
    "                                   how='inner').drop(columns='sub_task_id')\n",
    "            df_choice_1 = df_choice_1.rename(columns={c: f'{c.split(\"--\")[0]}_0' for c in cols_manip})\n",
    "            df_choice_1 = pd.merge(left=df_choice_1, \n",
    "                                   right=df[['sub_task_id', *cols_none]], \n",
    "                                   left_on='sub_task_id_1', \n",
    "                                   right_on='sub_task_id', \n",
    "                                   how='inner').drop(columns='sub_task_id')\n",
    "            df_choice_1 = df_choice_1.rename(columns={c: f'{c.split(\"--\")[0]}_1' for c in cols_none})\n",
    "            df_choice_2 = pd.merge(left=df_choice[df_choice['manipulate_on'] == 1], \n",
    "                                   right=df[['sub_task_id', *cols_manip]], \n",
    "                                   left_on='sub_task_id_1', \n",
    "                                   right_on='sub_task_id', \n",
    "                                   how='inner').drop(columns='sub_task_id')\n",
    "            df_choice_2 = df_choice_2.rename(columns={c: f'{c.split(\"--\")[0]}_1' for c in cols_manip})\n",
    "            df_choice_2 = pd.merge(left=df_choice_2, \n",
    "                                   right=df[['sub_task_id', *cols_none]], \n",
    "                                   left_on='sub_task_id_0', \n",
    "                                   right_on='sub_task_id', \n",
    "                                   how='inner').drop(columns='sub_task_id')\n",
    "            df_choice_2 = df_choice_2.rename(columns={c: f'{c.split(\"--\")[0]}_0' for c in cols_none})\n",
    "            df_choice = pd.concat((df_choice_1, df_choice_2), ignore_index=True)\n",
    "            \n",
    "        # split to ties (once chose each) (will be represented by 1.5 as a mean of 1 and 2) \n",
    "        # and non-ties (clear choice of one over the other)\n",
    "        df_choice_tie = df_choice[df_choice[f'choice--{manipulation}'] == 1.5]\n",
    "        df_choice = df_choice[df_choice[f'choice--{manipulation}'] != 1.5]\n",
    "        df_choice[f'choice--{manipulation}'] = df_choice[f'choice--{manipulation}'].astype(int) - 1  # make it 0 or 1\n",
    "        \n",
    "        # compute the difference in motivation scores between the chosen and not chosen tasks\n",
    "        for col in ['motivation_score']:\n",
    "            df_choice[f'{col}_diff'] = df_choice.apply(lambda r: r[f'{col}_{int(r[f\"choice--{manipulation}\"])}'] - \n",
    "                                                                 r[f'{col}_{int(1 - r[f\"choice--{manipulation}\"])}'], axis=1)\n",
    "        all_diffs.append(df_choice.apply(lambda r: r[f'motivation_score_0'] - \n",
    "                                                   r[f'motivation_score_1'], axis=1))\n",
    "        all_choices.append(df_choice[f'choice--{manipulation}'].values)\n",
    "        \n",
    "        # build a confidence interval for the mean of each column\n",
    "        def confidence_interval(df, col):\n",
    "            mean = df[col].mean()\n",
    "            std_err = df[col].std() / np.sqrt(len(df[col]))\n",
    "            margin_of_error = std_err * 1.96  # for 95% confidence\n",
    "            return mean - margin_of_error, mean + margin_of_error\n",
    "        \n",
    "        df_choice[[c for c in df_choice if 'diff' in c]].apply(lambda col: confidence_interval(df_choice, col.name))\n",
    "        df_choice_tie[[c for c in df_choice_tie if 'diff' in c]].apply(lambda col: confidence_interval(df_choice_tie, col.name))\n",
    "        \n",
    "        # apply a t-test to each column \n",
    "        def ttest_double_sided(df, col, verbose=False):\n",
    "            t_stat, p_value = ttest_1samp(df[col], 0)\n",
    "            if verbose:\n",
    "                print(f'T-test (double-sided) for {col}: t-statistic = {t_stat}, p-value = {p_value}')\n",
    "                print('Reject null hypothesis' if p_value < 0.05 else 'Fail to reject null hypothesis')\n",
    "            else:\n",
    "                return t_stat, p_value\n",
    "        \n",
    "        df_res = pd.DataFrame(columns=['column', 't_stat', 'p_value', 'reject_null'])\n",
    "        for col in df_choice[[c for c in df_choice if 'diff' in c]].columns:\n",
    "            if col == 'motivation_diff':\n",
    "                continue\n",
    "            t, p = ttest_double_sided(df_choice, col, verbose=False)\n",
    "            df_res = pd.concat((df_res, pd.DataFrame({\n",
    "                'column': [col],\n",
    "                't_stat': [t],\n",
    "                'p_value': [p],\n",
    "                'reject_null': [p < 0.05]\n",
    "            })))\n",
    "       \n",
    "        # save manipulated chosen percentage to csv for later aggregation\n",
    "        (df_choice['manipulate_on'] == df_choice[f'choice--{manipulation}']).to_csv(f'results/choice_analysis_details/{model}--{manipulation}--manipulated_chosen.csv', index=False)\n",
    "        \n",
    "        all_results.append({\n",
    "            'model': model,\n",
    "            'manipulation': manipulation,\n",
    "            'type': 'clear_choice',\n",
    "            'mean_diff': df_choice['motivation_score_diff'].mean(),\n",
    "            'ci_lower': confidence_interval(df_choice, 'motivation_score_diff')[0],\n",
    "            'ci_upper': confidence_interval(df_choice, 'motivation_score_diff')[1],\n",
    "            't_stat': df_res[df_res['column'] == 'motivation_score_diff']['t_stat'].values[0],\n",
    "            'p_value': df_res[df_res['column'] == 'motivation_score_diff']['p_value'].values[0],\n",
    "            'chosen_mean': df_choice.apply(lambda r: r[f'motivation_score_{int(r[f\"choice--{manipulation}\"])}'], axis=1).mean(),\n",
    "            'not_chosen_mean': df_choice.apply(lambda r: r[f'motivation_score_{int(1 - r[f\"choice--{manipulation}\"])}'], axis=1).mean(),\n",
    "            'manipulated_chosen_percentage': np.mean(df_choice['manipulate_on'] == df_choice[f'choice--{manipulation}']) * 100,\n",
    "            'chose_higher_motivation': np.mean(df_choice.apply(lambda r: r[f'motivation_score_{int(r[f\"choice--{manipulation}\"])}'] > r[f'motivation_score_{int(1 - r[f\"choice--{manipulation}\"])}'], axis=1)),\n",
    "        })\n",
    "        \n",
    "        # now repeat t-test and mean/ci for the ties only\n",
    "        for col in ['motivation_score']:\n",
    "            df_choice_tie[f'{col}_diff'] = df_choice_tie.apply(lambda r: r[f'{col}_{int(r[f\"first_choice--{manipulation}\"])}'] - r[f'{col}_{int(1 - r[f\"first_choice--{manipulation}\"])}'], axis=1)\n",
    "            # arbitrarily choose the first response's choice as the one with the higher value\n",
    "        df_res_tie = pd.DataFrame(columns=['column', 't_stat', 'p_value', 'reject_null'])\n",
    "        for col in df_choice_tie[[c for c in df_choice_tie if 'diff' in c]].columns:\n",
    "            if col == 'motivation_diff':\n",
    "                continue\n",
    "            t, p = ttest_double_sided(df_choice_tie, col, verbose=False)\n",
    "            df_res_tie = pd.concat((df_res_tie, pd.DataFrame({\n",
    "                'column': [col],\n",
    "                't_stat': [t],\n",
    "                'p_value': [p],\n",
    "                'reject_null': [p < 0.05]\n",
    "            })))\n",
    "        \n",
    "        all_results.append({\n",
    "            'model': model,\n",
    "            'manipulation': manipulation,\n",
    "            'type': 'tie',\n",
    "            'mean_diff': df_choice_tie['motivation_score_diff'].mean(),\n",
    "            'ci_lower': confidence_interval(df_choice_tie, 'motivation_score_diff')[0],\n",
    "            'ci_upper': confidence_interval(df_choice_tie, 'motivation_score_diff')[1],\n",
    "            't_stat': df_res_tie[df_res_tie['column'] == 'motivation_score_diff']['t_stat'].values[0],\n",
    "            'p_value': df_res_tie[df_res_tie['column'] == 'motivation_score_diff']['p_value'].values[0],\n",
    "            'chosen_mean': None,\n",
    "            'not_chosen_mean': None,\n",
    "            'manipulated_chosen_percentage': None,\n",
    "        })    "
   ],
   "id": "5e683690523e6d9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: vertex_ai_gemini-2.0-flash, Manipulation: none\n",
      "Model: vertex_ai_gemini-2.0-flash, Manipulation: punish\n",
      "Model: vertex_ai_gemini-2.0-flash, Manipulation: money\n",
      "Model: vertex_ai_gemini-2.0-flash, Manipulation: demotivate-futility\n",
      "Model: azure_gpt-4o, Manipulation: none\n",
      "Model: azure_gpt-4o, Manipulation: punish\n",
      "Model: azure_gpt-4o, Manipulation: money\n",
      "Model: azure_gpt-4o, Manipulation: demotivate-futility\n",
      "Model: azure_gpt-4o-mini, Manipulation: none\n",
      "Model: azure_gpt-4o-mini, Manipulation: punish\n",
      "Model: azure_gpt-4o-mini, Manipulation: money\n",
      "Model: azure_gpt-4o-mini, Manipulation: demotivate-futility\n",
      "Model: ollama_chat_llama3.1_8b-instruct-fp16, Manipulation: none\n",
      "Model: ollama_chat_llama3.1_8b-instruct-fp16, Manipulation: punish\n",
      "Model: ollama_chat_llama3.1_8b-instruct-fp16, Manipulation: money\n",
      "Model: ollama_chat_llama3.1_8b-instruct-fp16, Manipulation: demotivate-futility\n",
      "Model: ollama_chat_mistral_7b-instruct, Manipulation: none\n",
      "Model: ollama_chat_mistral_7b-instruct, Manipulation: punish\n",
      "Model: ollama_chat_mistral_7b-instruct, Manipulation: money\n",
      "Model: ollama_chat_mistral_7b-instruct, Manipulation: demotivate-futility\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:41:35.276133Z",
     "start_time": "2026-02-19T21:41:35.164578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_all_results = pd.DataFrame(all_results)\n",
    "# df_all_results.to_csv('results/choice_analysis_summary.csv', index=False)\n",
    "df_all_results.rename(columns={'p_value': 'p_value_raw'}, inplace=True)"
   ],
   "id": "4685c5d75847582e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:41:40.178390Z",
     "start_time": "2026-02-19T21:41:40.048133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Adjust p-values using Benjamini-Hochberg procedure (FDR)\n",
    "raw_pvals = df_all_results['p_value_raw'].values\n",
    "_, corrected_pvals, _, _ = multipletests(raw_pvals, method='fdr_bh')\n",
    "\n",
    "df_all_results['p_value_corrected'] = corrected_pvals\n",
    "df_all_results['significant'] = df_all_results['p_value_corrected'] < 0.05"
   ],
   "id": "df8cc58985eb207d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:42:00.826661Z",
     "start_time": "2026-02-19T21:42:00.690978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for manipulation in df_all_results['manipulation'].unique():\n",
    "    print(f'\\nManipulation: {manipulation}')\n",
    "    for type_ in df_all_results['type'].unique():\n",
    "        print(f'  Type: {type_}')\n",
    "        x = (df_all_results[(df_all_results['manipulation'] == manipulation) &\n",
    "                            (df_all_results['type'] == type_)]['significant'].value_counts())\n",
    "        if (x.index == True).all():\n",
    "            print('    All significant')\n",
    "        elif (x.index == False).all():\n",
    "            print('    None significant')\n",
    "        else:\n",
    "            print(f'    {x.get(True, 0)} significant, {x.get(False, 0)} not significant')"
   ],
   "id": "d1817de38c7e4da1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manipulation: none\n",
      "  Type: clear_choice\n",
      "    All significant\n",
      "  Type: tie\n",
      "    None significant\n",
      "\n",
      "Manipulation: punish\n",
      "  Type: clear_choice\n",
      "    All significant\n",
      "  Type: tie\n",
      "    None significant\n",
      "\n",
      "Manipulation: money\n",
      "  Type: clear_choice\n",
      "    All significant\n",
      "  Type: tie\n",
      "    None significant\n",
      "\n",
      "Manipulation: demotivate-futility\n",
      "  Type: clear_choice\n",
      "    All significant\n",
      "  Type: tie\n",
      "    None significant\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T05:19:20.249291Z",
     "start_time": "2025-10-23T05:19:20.100543Z"
    }
   },
   "cell_type": "code",
   "source": "# df_all_results",
   "id": "da5fb65bf00c3d15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                    model         manipulation          type  \\\n",
       "0              vertex_ai_gemini-2.0-flash                 none  clear_choice   \n",
       "1              vertex_ai_gemini-2.0-flash                 none           tie   \n",
       "2              vertex_ai_gemini-2.0-flash               punish  clear_choice   \n",
       "3              vertex_ai_gemini-2.0-flash               punish           tie   \n",
       "4              vertex_ai_gemini-2.0-flash                money  clear_choice   \n",
       "5              vertex_ai_gemini-2.0-flash                money           tie   \n",
       "6              vertex_ai_gemini-2.0-flash  demotivate-futility  clear_choice   \n",
       "7              vertex_ai_gemini-2.0-flash  demotivate-futility           tie   \n",
       "8                            azure_gpt-4o                 none  clear_choice   \n",
       "9                            azure_gpt-4o                 none           tie   \n",
       "10                           azure_gpt-4o               punish  clear_choice   \n",
       "11                           azure_gpt-4o               punish           tie   \n",
       "12                           azure_gpt-4o                money  clear_choice   \n",
       "13                           azure_gpt-4o                money           tie   \n",
       "14                           azure_gpt-4o  demotivate-futility  clear_choice   \n",
       "15                           azure_gpt-4o  demotivate-futility           tie   \n",
       "16                      azure_gpt-4o-mini                 none  clear_choice   \n",
       "17                      azure_gpt-4o-mini                 none           tie   \n",
       "18                      azure_gpt-4o-mini               punish  clear_choice   \n",
       "19                      azure_gpt-4o-mini               punish           tie   \n",
       "20                      azure_gpt-4o-mini                money  clear_choice   \n",
       "21                      azure_gpt-4o-mini                money           tie   \n",
       "22                      azure_gpt-4o-mini  demotivate-futility  clear_choice   \n",
       "23                      azure_gpt-4o-mini  demotivate-futility           tie   \n",
       "24  ollama_chat_llama3.1_8b-instruct-fp16                 none  clear_choice   \n",
       "25  ollama_chat_llama3.1_8b-instruct-fp16                 none           tie   \n",
       "26  ollama_chat_llama3.1_8b-instruct-fp16               punish  clear_choice   \n",
       "27  ollama_chat_llama3.1_8b-instruct-fp16               punish           tie   \n",
       "28  ollama_chat_llama3.1_8b-instruct-fp16                money  clear_choice   \n",
       "29  ollama_chat_llama3.1_8b-instruct-fp16                money           tie   \n",
       "30  ollama_chat_llama3.1_8b-instruct-fp16  demotivate-futility  clear_choice   \n",
       "31  ollama_chat_llama3.1_8b-instruct-fp16  demotivate-futility           tie   \n",
       "32        ollama_chat_mistral_7b-instruct                 none  clear_choice   \n",
       "33        ollama_chat_mistral_7b-instruct                 none           tie   \n",
       "34        ollama_chat_mistral_7b-instruct               punish  clear_choice   \n",
       "35        ollama_chat_mistral_7b-instruct               punish           tie   \n",
       "36        ollama_chat_mistral_7b-instruct                money  clear_choice   \n",
       "37        ollama_chat_mistral_7b-instruct                money           tie   \n",
       "38        ollama_chat_mistral_7b-instruct  demotivate-futility  clear_choice   \n",
       "39        ollama_chat_mistral_7b-instruct  demotivate-futility           tie   \n",
       "\n",
       "    mean_diff   ci_lower   ci_upper     t_stat   p_value_raw  chosen_mean  \\\n",
       "0   15.924275  14.264808  17.583741  18.808202  1.337768e-70    82.879689   \n",
       "1    0.401786  -3.082728   3.886300   0.226000  8.220392e-01          NaN   \n",
       "2   12.609211  10.790615  14.427808  13.589632  1.184178e-39    91.673761   \n",
       "3    4.416667  -1.811148  10.644482   1.390001  1.733066e-01          NaN   \n",
       "4   18.418815  16.797728  20.039902  22.269550  1.348231e-94    89.403833   \n",
       "5   -3.529412  -7.265597   0.206774  -1.851527  7.305983e-02          NaN   \n",
       "6   13.284594  11.712822  14.856367  16.565891  1.240280e-56    76.986708   \n",
       "7    3.750000 -33.000000  40.500000   0.200000  8.743341e-01          NaN   \n",
       "8   14.029369  12.662844  15.395895  20.122246  3.702317e-79    89.415518   \n",
       "9   -0.482759  -3.703238   2.737721  -0.293809  7.699708e-01          NaN   \n",
       "10   6.323615   4.820445   7.826786   8.245428  3.812150e-16    92.513484   \n",
       "11   0.415385  -4.758591   5.589361   0.157356  8.754600e-01          NaN   \n",
       "12  14.287419  12.972863  15.601974  21.302516  2.644417e-87    94.969993   \n",
       "13  -0.629630  -4.709299   3.450040  -0.302494  7.634598e-01          NaN   \n",
       "14   8.294161   6.932217   9.656104  11.936293  2.580329e-31    88.384672   \n",
       "15  -0.335821  -4.386095   3.714453  -0.162510  8.714010e-01          NaN   \n",
       "16   8.228989   7.054694   9.403284  13.734894  2.262362e-40    86.027066   \n",
       "17   0.875000  -2.979073   4.729073   0.444984  6.587915e-01          NaN   \n",
       "18  13.009568  11.460739  14.558396  16.463254  7.746834e-56    88.990078   \n",
       "19   6.034483  -1.599746  13.668712   1.549284  1.325437e-01          NaN   \n",
       "20   9.865371   8.798147  10.932595  18.118145  3.866989e-66    90.643816   \n",
       "21  -0.907407  -4.804669   2.989854  -0.456351  6.519271e-01          NaN   \n",
       "22   8.137553   7.063477   9.211629  14.849605  1.838386e-46    84.594767   \n",
       "23   4.517241  -4.523341  13.557824   0.979339  3.357991e-01          NaN   \n",
       "24  10.171811   7.243538  13.100083   6.808365  2.926927e-11    73.452675   \n",
       "25  -3.719512  -8.950151   1.511126  -1.393758  1.659243e-01          NaN   \n",
       "26  16.157732  13.529810  18.785654  12.051027  1.976516e-29    84.798969   \n",
       "27  -5.247664  -9.951241  -0.544086  -2.186723  3.096122e-02          NaN   \n",
       "28   6.151571   3.805414   8.497728   5.139076  3.864546e-07    71.974122   \n",
       "29   0.317460  -6.236063   6.870983   0.094945  9.246650e-01          NaN   \n",
       "30  29.722591  27.404163  32.041020  25.127484  8.685087e-96    68.147010   \n",
       "31   8.333333 -54.246997  70.913664   0.260998  8.185115e-01          NaN   \n",
       "32  11.067678   8.778899  13.356457   9.477827  2.471749e-20    88.386814   \n",
       "33   7.680000  -3.334851  18.694851   1.366591  1.844207e-01          NaN   \n",
       "34  12.132442   9.873104  14.391781  10.525023  2.172761e-24    91.236938   \n",
       "35   0.855263  -5.305428   7.015954   0.272099  7.870588e-01          NaN   \n",
       "36  10.835113   8.720794  12.949432  10.044284  1.694436e-22    90.201068   \n",
       "37 -50.875000 -86.386480 -15.363520  -2.807965  6.740627e-02          NaN   \n",
       "38   8.828437   6.634176  11.022698   7.885907  9.569124e-15    86.921269   \n",
       "39   0.882353 -10.829367  12.594073   0.147665  8.844519e-01          NaN   \n",
       "\n",
       "    not_chosen_mean  manipulated_chosen_percentage  chose_higher_motivation  \\\n",
       "0         66.955414                      50.955414                 0.631989   \n",
       "1               NaN                            NaN                      NaN   \n",
       "2         79.064550                      62.526169                 0.651082   \n",
       "3               NaN                            NaN                      NaN   \n",
       "4         70.985017                      67.944251                 0.758885   \n",
       "5               NaN                            NaN                      NaN   \n",
       "6         63.702113                       2.385821                 0.754601   \n",
       "7               NaN                            NaN                      NaN   \n",
       "8         75.386149                      51.124003                 0.660624   \n",
       "9               NaN                            NaN                      NaN   \n",
       "10        86.189869                      43.221574                 0.494169   \n",
       "11              NaN                            NaN                      NaN   \n",
       "12        80.682574                      70.715835                 0.720174   \n",
       "13              NaN                            NaN                      NaN   \n",
       "14        80.090511                      24.744526                 0.548905   \n",
       "15              NaN                            NaN                      NaN   \n",
       "16        77.798077                      50.071225                 0.492165   \n",
       "17              NaN                            NaN                      NaN   \n",
       "18        75.980510                      75.620128                 0.785259   \n",
       "19              NaN                            NaN                      NaN   \n",
       "20        80.778445                      83.745583                 0.792226   \n",
       "21              NaN                            NaN                      NaN   \n",
       "22        76.457214                      13.861386                 0.666195   \n",
       "23              NaN                            NaN                      NaN   \n",
       "24        63.280864                      48.148148                 0.598765   \n",
       "25              NaN                            NaN                      NaN   \n",
       "26        68.641237                      78.556701                 0.727835   \n",
       "27              NaN                            NaN                      NaN   \n",
       "28        65.822551                      87.985213                 0.519409   \n",
       "29              NaN                            NaN                      NaN   \n",
       "30        38.424419                       0.664452                 0.832226   \n",
       "31              NaN                            NaN                      NaN   \n",
       "32        77.319137                      49.708285                 0.498250   \n",
       "33              NaN                            NaN                      NaN   \n",
       "34        79.104496                      50.425273                 0.477521   \n",
       "35              NaN                            NaN                      NaN   \n",
       "36        79.365955                      95.136418                 0.454330   \n",
       "37              NaN                            NaN                      NaN   \n",
       "38        78.092832                      21.034078                 0.548766   \n",
       "39              NaN                            NaN                      NaN   \n",
       "\n",
       "    p_value_corrected  significant  \n",
       "0        1.070215e-69         True  \n",
       "1        9.071302e-01        False  \n",
       "2        4.306104e-39         True  \n",
       "3        2.666255e-01        False  \n",
       "4        2.696462e-93         True  \n",
       "5        1.270606e-01        False  \n",
       "6        7.087314e-56         True  \n",
       "7        9.071302e-01        False  \n",
       "8        3.702317e-78         True  \n",
       "9        9.071302e-01        False  \n",
       "10       8.969764e-16         True  \n",
       "11       9.071302e-01        False  \n",
       "12       3.525889e-86         True  \n",
       "13       9.071302e-01        False  \n",
       "14       8.601097e-31         True  \n",
       "15       9.071302e-01        False  \n",
       "16       9.049448e-40         True  \n",
       "17       8.783887e-01        False  \n",
       "18       3.873417e-55         True  \n",
       "19       2.209062e-01        False  \n",
       "20       2.577993e-65         True  \n",
       "21       8.783887e-01        False  \n",
       "22       8.170606e-46         True  \n",
       "23       4.797130e-01        False  \n",
       "24       6.161951e-11         True  \n",
       "25       2.654790e-01        False  \n",
       "26       6.081588e-29         True  \n",
       "27       5.897375e-02        False  \n",
       "28       7.729092e-07         True  \n",
       "29       9.246650e-01        False  \n",
       "30       3.474035e-94         True  \n",
       "31       9.071302e-01        False  \n",
       "32       6.179373e-20         True  \n",
       "33       2.732159e-01        False  \n",
       "34       6.207889e-24         True  \n",
       "35       9.071302e-01        False  \n",
       "36       4.518495e-22         True  \n",
       "37       1.225569e-01        False  \n",
       "38       2.126472e-14         True  \n",
       "39       9.071302e-01        False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>manipulation</th>\n",
       "      <th>type</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_value_raw</th>\n",
       "      <th>chosen_mean</th>\n",
       "      <th>not_chosen_mean</th>\n",
       "      <th>manipulated_chosen_percentage</th>\n",
       "      <th>chose_higher_motivation</th>\n",
       "      <th>p_value_corrected</th>\n",
       "      <th>significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>none</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>15.924275</td>\n",
       "      <td>14.264808</td>\n",
       "      <td>17.583741</td>\n",
       "      <td>18.808202</td>\n",
       "      <td>1.337768e-70</td>\n",
       "      <td>82.879689</td>\n",
       "      <td>66.955414</td>\n",
       "      <td>50.955414</td>\n",
       "      <td>0.631989</td>\n",
       "      <td>1.070215e-69</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>none</td>\n",
       "      <td>tie</td>\n",
       "      <td>0.401786</td>\n",
       "      <td>-3.082728</td>\n",
       "      <td>3.886300</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>8.220392e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>punish</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>12.609211</td>\n",
       "      <td>10.790615</td>\n",
       "      <td>14.427808</td>\n",
       "      <td>13.589632</td>\n",
       "      <td>1.184178e-39</td>\n",
       "      <td>91.673761</td>\n",
       "      <td>79.064550</td>\n",
       "      <td>62.526169</td>\n",
       "      <td>0.651082</td>\n",
       "      <td>4.306104e-39</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>punish</td>\n",
       "      <td>tie</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>-1.811148</td>\n",
       "      <td>10.644482</td>\n",
       "      <td>1.390001</td>\n",
       "      <td>1.733066e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.666255e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>money</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>18.418815</td>\n",
       "      <td>16.797728</td>\n",
       "      <td>20.039902</td>\n",
       "      <td>22.269550</td>\n",
       "      <td>1.348231e-94</td>\n",
       "      <td>89.403833</td>\n",
       "      <td>70.985017</td>\n",
       "      <td>67.944251</td>\n",
       "      <td>0.758885</td>\n",
       "      <td>2.696462e-93</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>money</td>\n",
       "      <td>tie</td>\n",
       "      <td>-3.529412</td>\n",
       "      <td>-7.265597</td>\n",
       "      <td>0.206774</td>\n",
       "      <td>-1.851527</td>\n",
       "      <td>7.305983e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.270606e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>13.284594</td>\n",
       "      <td>11.712822</td>\n",
       "      <td>14.856367</td>\n",
       "      <td>16.565891</td>\n",
       "      <td>1.240280e-56</td>\n",
       "      <td>76.986708</td>\n",
       "      <td>63.702113</td>\n",
       "      <td>2.385821</td>\n",
       "      <td>0.754601</td>\n",
       "      <td>7.087314e-56</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>tie</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>-33.000000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.743341e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>none</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>14.029369</td>\n",
       "      <td>12.662844</td>\n",
       "      <td>15.395895</td>\n",
       "      <td>20.122246</td>\n",
       "      <td>3.702317e-79</td>\n",
       "      <td>89.415518</td>\n",
       "      <td>75.386149</td>\n",
       "      <td>51.124003</td>\n",
       "      <td>0.660624</td>\n",
       "      <td>3.702317e-78</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>none</td>\n",
       "      <td>tie</td>\n",
       "      <td>-0.482759</td>\n",
       "      <td>-3.703238</td>\n",
       "      <td>2.737721</td>\n",
       "      <td>-0.293809</td>\n",
       "      <td>7.699708e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>punish</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>6.323615</td>\n",
       "      <td>4.820445</td>\n",
       "      <td>7.826786</td>\n",
       "      <td>8.245428</td>\n",
       "      <td>3.812150e-16</td>\n",
       "      <td>92.513484</td>\n",
       "      <td>86.189869</td>\n",
       "      <td>43.221574</td>\n",
       "      <td>0.494169</td>\n",
       "      <td>8.969764e-16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>punish</td>\n",
       "      <td>tie</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>-4.758591</td>\n",
       "      <td>5.589361</td>\n",
       "      <td>0.157356</td>\n",
       "      <td>8.754600e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>money</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>14.287419</td>\n",
       "      <td>12.972863</td>\n",
       "      <td>15.601974</td>\n",
       "      <td>21.302516</td>\n",
       "      <td>2.644417e-87</td>\n",
       "      <td>94.969993</td>\n",
       "      <td>80.682574</td>\n",
       "      <td>70.715835</td>\n",
       "      <td>0.720174</td>\n",
       "      <td>3.525889e-86</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>money</td>\n",
       "      <td>tie</td>\n",
       "      <td>-0.629630</td>\n",
       "      <td>-4.709299</td>\n",
       "      <td>3.450040</td>\n",
       "      <td>-0.302494</td>\n",
       "      <td>7.634598e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>8.294161</td>\n",
       "      <td>6.932217</td>\n",
       "      <td>9.656104</td>\n",
       "      <td>11.936293</td>\n",
       "      <td>2.580329e-31</td>\n",
       "      <td>88.384672</td>\n",
       "      <td>80.090511</td>\n",
       "      <td>24.744526</td>\n",
       "      <td>0.548905</td>\n",
       "      <td>8.601097e-31</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>tie</td>\n",
       "      <td>-0.335821</td>\n",
       "      <td>-4.386095</td>\n",
       "      <td>3.714453</td>\n",
       "      <td>-0.162510</td>\n",
       "      <td>8.714010e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>none</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>8.228989</td>\n",
       "      <td>7.054694</td>\n",
       "      <td>9.403284</td>\n",
       "      <td>13.734894</td>\n",
       "      <td>2.262362e-40</td>\n",
       "      <td>86.027066</td>\n",
       "      <td>77.798077</td>\n",
       "      <td>50.071225</td>\n",
       "      <td>0.492165</td>\n",
       "      <td>9.049448e-40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>none</td>\n",
       "      <td>tie</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>-2.979073</td>\n",
       "      <td>4.729073</td>\n",
       "      <td>0.444984</td>\n",
       "      <td>6.587915e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.783887e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>punish</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>13.009568</td>\n",
       "      <td>11.460739</td>\n",
       "      <td>14.558396</td>\n",
       "      <td>16.463254</td>\n",
       "      <td>7.746834e-56</td>\n",
       "      <td>88.990078</td>\n",
       "      <td>75.980510</td>\n",
       "      <td>75.620128</td>\n",
       "      <td>0.785259</td>\n",
       "      <td>3.873417e-55</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>punish</td>\n",
       "      <td>tie</td>\n",
       "      <td>6.034483</td>\n",
       "      <td>-1.599746</td>\n",
       "      <td>13.668712</td>\n",
       "      <td>1.549284</td>\n",
       "      <td>1.325437e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.209062e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>money</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>9.865371</td>\n",
       "      <td>8.798147</td>\n",
       "      <td>10.932595</td>\n",
       "      <td>18.118145</td>\n",
       "      <td>3.866989e-66</td>\n",
       "      <td>90.643816</td>\n",
       "      <td>80.778445</td>\n",
       "      <td>83.745583</td>\n",
       "      <td>0.792226</td>\n",
       "      <td>2.577993e-65</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>money</td>\n",
       "      <td>tie</td>\n",
       "      <td>-0.907407</td>\n",
       "      <td>-4.804669</td>\n",
       "      <td>2.989854</td>\n",
       "      <td>-0.456351</td>\n",
       "      <td>6.519271e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.783887e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>8.137553</td>\n",
       "      <td>7.063477</td>\n",
       "      <td>9.211629</td>\n",
       "      <td>14.849605</td>\n",
       "      <td>1.838386e-46</td>\n",
       "      <td>84.594767</td>\n",
       "      <td>76.457214</td>\n",
       "      <td>13.861386</td>\n",
       "      <td>0.666195</td>\n",
       "      <td>8.170606e-46</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>tie</td>\n",
       "      <td>4.517241</td>\n",
       "      <td>-4.523341</td>\n",
       "      <td>13.557824</td>\n",
       "      <td>0.979339</td>\n",
       "      <td>3.357991e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.797130e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>none</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>10.171811</td>\n",
       "      <td>7.243538</td>\n",
       "      <td>13.100083</td>\n",
       "      <td>6.808365</td>\n",
       "      <td>2.926927e-11</td>\n",
       "      <td>73.452675</td>\n",
       "      <td>63.280864</td>\n",
       "      <td>48.148148</td>\n",
       "      <td>0.598765</td>\n",
       "      <td>6.161951e-11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>none</td>\n",
       "      <td>tie</td>\n",
       "      <td>-3.719512</td>\n",
       "      <td>-8.950151</td>\n",
       "      <td>1.511126</td>\n",
       "      <td>-1.393758</td>\n",
       "      <td>1.659243e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.654790e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>punish</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>16.157732</td>\n",
       "      <td>13.529810</td>\n",
       "      <td>18.785654</td>\n",
       "      <td>12.051027</td>\n",
       "      <td>1.976516e-29</td>\n",
       "      <td>84.798969</td>\n",
       "      <td>68.641237</td>\n",
       "      <td>78.556701</td>\n",
       "      <td>0.727835</td>\n",
       "      <td>6.081588e-29</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>punish</td>\n",
       "      <td>tie</td>\n",
       "      <td>-5.247664</td>\n",
       "      <td>-9.951241</td>\n",
       "      <td>-0.544086</td>\n",
       "      <td>-2.186723</td>\n",
       "      <td>3.096122e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.897375e-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>money</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>6.151571</td>\n",
       "      <td>3.805414</td>\n",
       "      <td>8.497728</td>\n",
       "      <td>5.139076</td>\n",
       "      <td>3.864546e-07</td>\n",
       "      <td>71.974122</td>\n",
       "      <td>65.822551</td>\n",
       "      <td>87.985213</td>\n",
       "      <td>0.519409</td>\n",
       "      <td>7.729092e-07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>money</td>\n",
       "      <td>tie</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>-6.236063</td>\n",
       "      <td>6.870983</td>\n",
       "      <td>0.094945</td>\n",
       "      <td>9.246650e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.246650e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>29.722591</td>\n",
       "      <td>27.404163</td>\n",
       "      <td>32.041020</td>\n",
       "      <td>25.127484</td>\n",
       "      <td>8.685087e-96</td>\n",
       "      <td>68.147010</td>\n",
       "      <td>38.424419</td>\n",
       "      <td>0.664452</td>\n",
       "      <td>0.832226</td>\n",
       "      <td>3.474035e-94</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>tie</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>-54.246997</td>\n",
       "      <td>70.913664</td>\n",
       "      <td>0.260998</td>\n",
       "      <td>8.185115e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>none</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>11.067678</td>\n",
       "      <td>8.778899</td>\n",
       "      <td>13.356457</td>\n",
       "      <td>9.477827</td>\n",
       "      <td>2.471749e-20</td>\n",
       "      <td>88.386814</td>\n",
       "      <td>77.319137</td>\n",
       "      <td>49.708285</td>\n",
       "      <td>0.498250</td>\n",
       "      <td>6.179373e-20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>none</td>\n",
       "      <td>tie</td>\n",
       "      <td>7.680000</td>\n",
       "      <td>-3.334851</td>\n",
       "      <td>18.694851</td>\n",
       "      <td>1.366591</td>\n",
       "      <td>1.844207e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.732159e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>punish</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>12.132442</td>\n",
       "      <td>9.873104</td>\n",
       "      <td>14.391781</td>\n",
       "      <td>10.525023</td>\n",
       "      <td>2.172761e-24</td>\n",
       "      <td>91.236938</td>\n",
       "      <td>79.104496</td>\n",
       "      <td>50.425273</td>\n",
       "      <td>0.477521</td>\n",
       "      <td>6.207889e-24</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>punish</td>\n",
       "      <td>tie</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>-5.305428</td>\n",
       "      <td>7.015954</td>\n",
       "      <td>0.272099</td>\n",
       "      <td>7.870588e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>money</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>10.835113</td>\n",
       "      <td>8.720794</td>\n",
       "      <td>12.949432</td>\n",
       "      <td>10.044284</td>\n",
       "      <td>1.694436e-22</td>\n",
       "      <td>90.201068</td>\n",
       "      <td>79.365955</td>\n",
       "      <td>95.136418</td>\n",
       "      <td>0.454330</td>\n",
       "      <td>4.518495e-22</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>money</td>\n",
       "      <td>tie</td>\n",
       "      <td>-50.875000</td>\n",
       "      <td>-86.386480</td>\n",
       "      <td>-15.363520</td>\n",
       "      <td>-2.807965</td>\n",
       "      <td>6.740627e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.225569e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>8.828437</td>\n",
       "      <td>6.634176</td>\n",
       "      <td>11.022698</td>\n",
       "      <td>7.885907</td>\n",
       "      <td>9.569124e-15</td>\n",
       "      <td>86.921269</td>\n",
       "      <td>78.092832</td>\n",
       "      <td>21.034078</td>\n",
       "      <td>0.548766</td>\n",
       "      <td>2.126472e-14</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>tie</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>-10.829367</td>\n",
       "      <td>12.594073</td>\n",
       "      <td>0.147665</td>\n",
       "      <td>8.844519e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:42:32.050922Z",
     "start_time": "2026-02-19T21:42:31.918347Z"
    }
   },
   "cell_type": "code",
   "source": "df_all_results[df_all_results['type'] == 'clear_choice'].groupby('manipulation')['chose_higher_motivation'].mean()",
   "id": "3baac3b75e8d4695",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "manipulation\n",
       "demotivate-futility    0.670139\n",
       "money                  0.649005\n",
       "none                   0.576359\n",
       "punish                 0.627173\n",
       "Name: chose_higher_motivation, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T05:19:41.257747Z",
     "start_time": "2025-10-23T05:19:41.108859Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save to csv\n",
    "# df_all_results.to_csv('tables/choice_analysis_corrected.csv', index=False)"
   ],
   "id": "842681ddf146f1a4",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T04:42:59.190211Z",
     "start_time": "2025-10-23T04:42:57.921301Z"
    }
   },
   "cell_type": "code",
   "source": "# df_all_results = pd.read_csv('tables/choice_analysis_corrected.csv')",
   "id": "97e738d3363d10c1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:42:56.249378Z",
     "start_time": "2026-02-19T21:42:56.075562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_all_results.groupby(['manipulation', 'type']).agg({\n",
    "    'mean_diff': 'mean',\n",
    "    'ci_lower': 'mean',\n",
    "    'ci_upper': 'mean',\n",
    "    't_stat': 'min',\n",
    "    'p_value_corrected': 'max',\n",
    "    'significant': 'sum',\n",
    "    'manipulated_chosen_percentage': 'mean',\n",
    "    'chosen_mean': 'mean',\n",
    "    'not_chosen_mean': 'mean',\n",
    "}).reset_index()"
   ],
   "id": "cff04c25552b76bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          manipulation          type  mean_diff   ci_lower   ci_upper  \\\n",
       "0  demotivate-futility  clear_choice  13.653467  11.949371  15.357563   \n",
       "1  demotivate-futility           tie   3.429421 -21.397160  28.256003   \n",
       "2                money  clear_choice  11.911658  10.218989  13.604326   \n",
       "3                money           tie -11.124798 -21.880422  -0.369174   \n",
       "4                 none  clear_choice  11.884424  10.000957  13.767892   \n",
       "5                 none           tie   0.950903  -4.410008   6.311814   \n",
       "6               punish  clear_choice  12.046514  10.094943  13.998085   \n",
       "7               punish           tie   1.294827  -4.685231   7.274884   \n",
       "\n",
       "     t_stat  p_value_corrected  significant  manipulated_chosen_percentage  \\\n",
       "0  7.885907       2.126472e-14            5                      12.538052   \n",
       "1 -0.162510       9.071302e-01            0                            NaN   \n",
       "2  5.139076       7.729092e-07            5                      81.105460   \n",
       "3 -2.807965       9.246650e-01            0                            NaN   \n",
       "4  6.808365       6.161951e-11            5                      50.001415   \n",
       "5 -1.393758       9.071302e-01            0                            NaN   \n",
       "6  8.245428       8.969764e-16            5                      62.069969   \n",
       "7 -2.186723       9.071302e-01            0                            NaN   \n",
       "\n",
       "   chosen_mean  not_chosen_mean  \n",
       "0    81.006885        67.353418  \n",
       "1          NaN              NaN  \n",
       "2    87.438566        75.526909  \n",
       "3          NaN              NaN  \n",
       "4    84.032352        72.147928  \n",
       "5          NaN              NaN  \n",
       "6    89.842646        77.796132  \n",
       "7          NaN              NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manipulation</th>\n",
       "      <th>type</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>t_stat</th>\n",
       "      <th>p_value_corrected</th>\n",
       "      <th>significant</th>\n",
       "      <th>manipulated_chosen_percentage</th>\n",
       "      <th>chosen_mean</th>\n",
       "      <th>not_chosen_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>13.653467</td>\n",
       "      <td>11.949371</td>\n",
       "      <td>15.357563</td>\n",
       "      <td>7.885907</td>\n",
       "      <td>2.126472e-14</td>\n",
       "      <td>5</td>\n",
       "      <td>12.538052</td>\n",
       "      <td>81.006885</td>\n",
       "      <td>67.353418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>tie</td>\n",
       "      <td>3.429421</td>\n",
       "      <td>-21.397160</td>\n",
       "      <td>28.256003</td>\n",
       "      <td>-0.162510</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>money</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>11.911658</td>\n",
       "      <td>10.218989</td>\n",
       "      <td>13.604326</td>\n",
       "      <td>5.139076</td>\n",
       "      <td>7.729092e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>81.105460</td>\n",
       "      <td>87.438566</td>\n",
       "      <td>75.526909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>money</td>\n",
       "      <td>tie</td>\n",
       "      <td>-11.124798</td>\n",
       "      <td>-21.880422</td>\n",
       "      <td>-0.369174</td>\n",
       "      <td>-2.807965</td>\n",
       "      <td>9.246650e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>11.884424</td>\n",
       "      <td>10.000957</td>\n",
       "      <td>13.767892</td>\n",
       "      <td>6.808365</td>\n",
       "      <td>6.161951e-11</td>\n",
       "      <td>5</td>\n",
       "      <td>50.001415</td>\n",
       "      <td>84.032352</td>\n",
       "      <td>72.147928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>none</td>\n",
       "      <td>tie</td>\n",
       "      <td>0.950903</td>\n",
       "      <td>-4.410008</td>\n",
       "      <td>6.311814</td>\n",
       "      <td>-1.393758</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>punish</td>\n",
       "      <td>clear_choice</td>\n",
       "      <td>12.046514</td>\n",
       "      <td>10.094943</td>\n",
       "      <td>13.998085</td>\n",
       "      <td>8.245428</td>\n",
       "      <td>8.969764e-16</td>\n",
       "      <td>5</td>\n",
       "      <td>62.069969</td>\n",
       "      <td>89.842646</td>\n",
       "      <td>77.796132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>punish</td>\n",
       "      <td>tie</td>\n",
       "      <td>1.294827</td>\n",
       "      <td>-4.685231</td>\n",
       "      <td>7.274884</td>\n",
       "      <td>-2.186723</td>\n",
       "      <td>9.071302e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Logistic regression",
   "id": "53ab5f815199eb0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:48:33.176854Z",
     "start_time": "2026-02-19T21:48:32.985913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = 0\n",
    "results_lr = []\n",
    "for model in names.keys():\n",
    "    if model == 'all':\n",
    "        continue\n",
    "    for manipulation in ['none', 'punish', 'money', 'demotivate-futility']:\n",
    "        X = all_diffs[i].values.reshape(-1, 1)\n",
    "        y = 1 - all_choices[i]\n",
    "        \n",
    "        X = sm.add_constant(X)  # add intercept\n",
    "        lr_model = sm.Logit(y, X)\n",
    "        result = lr_model.fit(disp=0)\n",
    "        beta = result.params[1]\n",
    "        zval = result.tvalues[1]\n",
    "        pval = result.pvalues[1]\n",
    "\n",
    "        results_lr.append({\n",
    "            'model': model,\n",
    "            'manipulation': manipulation,\n",
    "            'coefficient': beta,\n",
    "            'z_value': zval,\n",
    "            'p_value': pval,\n",
    "        })\n",
    "        i += 1\n",
    "    # break"
   ],
   "id": "b3fcd5c01a271a3f",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:48:44.137189Z",
     "start_time": "2026-02-19T21:48:43.924724Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_results_lr = pd.DataFrame(results_lr)\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "raw_pvals = df_results_lr['p_value'].values\n",
    "df_results_lr.rename(columns={'p_value': 'p_value_raw'}, inplace=True)\n",
    "_, corrected_pvals, _, _ = multipletests(raw_pvals, method='fdr_bh')\n",
    "\n",
    "df_results_lr['p_value_corrected'] = corrected_pvals\n",
    "df_results_lr"
   ],
   "id": "4dd6286cd3172280",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                    model         manipulation  coefficient  \\\n",
       "0              vertex_ai_gemini-2.0-flash                 none     0.041648   \n",
       "1              vertex_ai_gemini-2.0-flash               punish     0.024108   \n",
       "2              vertex_ai_gemini-2.0-flash                money     0.055227   \n",
       "3              vertex_ai_gemini-2.0-flash  demotivate-futility     0.030506   \n",
       "4                            azure_gpt-4o                 none     0.111139   \n",
       "5                            azure_gpt-4o               punish     0.017614   \n",
       "6                            azure_gpt-4o                money     0.134794   \n",
       "7                            azure_gpt-4o  demotivate-futility     0.032900   \n",
       "8                       azure_gpt-4o-mini                 none     0.126585   \n",
       "9                       azure_gpt-4o-mini               punish     0.045660   \n",
       "10                      azure_gpt-4o-mini                money     0.274168   \n",
       "11                      azure_gpt-4o-mini  demotivate-futility     0.110654   \n",
       "12  ollama_chat_llama3.1_8b-instruct-fp16                 none     0.019597   \n",
       "13  ollama_chat_llama3.1_8b-instruct-fp16               punish     0.041034   \n",
       "14  ollama_chat_llama3.1_8b-instruct-fp16                money     0.016977   \n",
       "15  ollama_chat_llama3.1_8b-instruct-fp16  demotivate-futility     0.059709   \n",
       "16        ollama_chat_mistral_7b-instruct                 none     0.033516   \n",
       "17        ollama_chat_mistral_7b-instruct               punish     0.038758   \n",
       "18        ollama_chat_mistral_7b-instruct                money     0.027366   \n",
       "19        ollama_chat_mistral_7b-instruct  demotivate-futility     0.020467   \n",
       "\n",
       "      z_value   p_value_raw  p_value_corrected  \n",
       "0   13.848344  1.301790e-43       6.508950e-43  \n",
       "1   11.904350  1.123356e-32       2.808391e-32  \n",
       "2   15.215838  2.776403e-52       1.850936e-51  \n",
       "3   13.615642  3.232919e-42       1.077640e-41  \n",
       "4   13.727593  6.940089e-43       2.776036e-42  \n",
       "5    7.668251  1.743574e-14       2.051264e-14  \n",
       "6   15.974412  1.926620e-57       1.926620e-56  \n",
       "7    9.433782  3.955619e-21       6.085568e-21  \n",
       "8    9.207434  3.340149e-20       4.771641e-20  \n",
       "9   11.246983  2.396504e-29       4.793008e-29  \n",
       "10  18.789968  9.123429e-79       1.824686e-77  \n",
       "11  11.690390  1.427298e-31       3.171773e-31  \n",
       "12   6.255050  3.973897e-10       4.183049e-10  \n",
       "13   9.114906  7.873848e-20       1.049846e-19  \n",
       "14   4.975837  6.496637e-07       6.496637e-07  \n",
       "15  13.405518  5.612993e-41       1.603712e-40  \n",
       "16  10.366484  3.522461e-25       6.404475e-25  \n",
       "17  10.096890  5.702177e-24       9.503628e-24  \n",
       "18   8.012976  1.119655e-15       1.399569e-15  \n",
       "19   7.607495  2.794592e-14       3.105102e-14  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>manipulation</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>z_value</th>\n",
       "      <th>p_value_raw</th>\n",
       "      <th>p_value_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>none</td>\n",
       "      <td>0.041648</td>\n",
       "      <td>13.848344</td>\n",
       "      <td>1.301790e-43</td>\n",
       "      <td>6.508950e-43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>punish</td>\n",
       "      <td>0.024108</td>\n",
       "      <td>11.904350</td>\n",
       "      <td>1.123356e-32</td>\n",
       "      <td>2.808391e-32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>money</td>\n",
       "      <td>0.055227</td>\n",
       "      <td>15.215838</td>\n",
       "      <td>2.776403e-52</td>\n",
       "      <td>1.850936e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vertex_ai_gemini-2.0-flash</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>0.030506</td>\n",
       "      <td>13.615642</td>\n",
       "      <td>3.232919e-42</td>\n",
       "      <td>1.077640e-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>none</td>\n",
       "      <td>0.111139</td>\n",
       "      <td>13.727593</td>\n",
       "      <td>6.940089e-43</td>\n",
       "      <td>2.776036e-42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>punish</td>\n",
       "      <td>0.017614</td>\n",
       "      <td>7.668251</td>\n",
       "      <td>1.743574e-14</td>\n",
       "      <td>2.051264e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>money</td>\n",
       "      <td>0.134794</td>\n",
       "      <td>15.974412</td>\n",
       "      <td>1.926620e-57</td>\n",
       "      <td>1.926620e-56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>azure_gpt-4o</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>9.433782</td>\n",
       "      <td>3.955619e-21</td>\n",
       "      <td>6.085568e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>none</td>\n",
       "      <td>0.126585</td>\n",
       "      <td>9.207434</td>\n",
       "      <td>3.340149e-20</td>\n",
       "      <td>4.771641e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>punish</td>\n",
       "      <td>0.045660</td>\n",
       "      <td>11.246983</td>\n",
       "      <td>2.396504e-29</td>\n",
       "      <td>4.793008e-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>money</td>\n",
       "      <td>0.274168</td>\n",
       "      <td>18.789968</td>\n",
       "      <td>9.123429e-79</td>\n",
       "      <td>1.824686e-77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>azure_gpt-4o-mini</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>0.110654</td>\n",
       "      <td>11.690390</td>\n",
       "      <td>1.427298e-31</td>\n",
       "      <td>3.171773e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>none</td>\n",
       "      <td>0.019597</td>\n",
       "      <td>6.255050</td>\n",
       "      <td>3.973897e-10</td>\n",
       "      <td>4.183049e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>punish</td>\n",
       "      <td>0.041034</td>\n",
       "      <td>9.114906</td>\n",
       "      <td>7.873848e-20</td>\n",
       "      <td>1.049846e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>money</td>\n",
       "      <td>0.016977</td>\n",
       "      <td>4.975837</td>\n",
       "      <td>6.496637e-07</td>\n",
       "      <td>6.496637e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ollama_chat_llama3.1_8b-instruct-fp16</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>0.059709</td>\n",
       "      <td>13.405518</td>\n",
       "      <td>5.612993e-41</td>\n",
       "      <td>1.603712e-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>none</td>\n",
       "      <td>0.033516</td>\n",
       "      <td>10.366484</td>\n",
       "      <td>3.522461e-25</td>\n",
       "      <td>6.404475e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>punish</td>\n",
       "      <td>0.038758</td>\n",
       "      <td>10.096890</td>\n",
       "      <td>5.702177e-24</td>\n",
       "      <td>9.503628e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>money</td>\n",
       "      <td>0.027366</td>\n",
       "      <td>8.012976</td>\n",
       "      <td>1.119655e-15</td>\n",
       "      <td>1.399569e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ollama_chat_mistral_7b-instruct</td>\n",
       "      <td>demotivate-futility</td>\n",
       "      <td>0.020467</td>\n",
       "      <td>7.607495</td>\n",
       "      <td>2.794592e-14</td>\n",
       "      <td>3.105102e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:48:49.417936Z",
     "start_time": "2026-02-19T21:48:49.293533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df_results_lr['coefficient'].min())\n",
    "print(df_results_lr['z_value'].min())\n",
    "print(df_results_lr['p_value_corrected'].max())"
   ],
   "id": "22a6669a57c94701",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0169769990832276\n",
      "4.975836776297138\n",
      "6.496637485017125e-07\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:57:08.764165Z",
     "start_time": "2026-02-19T21:57:08.468597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_dir = 'results/choice_analysis_details'\n",
    "manipulations = ['punish', 'money', 'demotivate-futility']\n",
    "\n",
    "results = {}\n",
    "for manipulation in manipulations:\n",
    "    values = []\n",
    "    for model in names.keys():\n",
    "        if model == 'all':\n",
    "            continue\n",
    "        a = list(pd.read_csv(os.path.join(results_dir, f'{model}--{manipulation}--manipulated_chosen.csv')).values.reshape(-1))\n",
    "        values += a\n",
    "\n",
    "    values = np.array(values)\n",
    "    low, high = proportion_confint(\n",
    "        count=values.sum(),\n",
    "        nobs=len(values),\n",
    "        alpha=0.01,\n",
    "        method=\"wilson\"\n",
    "        )\n",
    "    print(f'Manipulation: {manipulation}, Manipulated chosen percentage: {values.mean()*100:.2f}%, 99% CI: ({low*100:.2f}%, {high*100:.2f}%)')\n",
    "    results[manipulation] = {\n",
    "        'mean': values.mean() * 100,\n",
    "        'ci_lower': low * 100,\n",
    "        'ci_upper': high * 100,\n",
    "    }"
   ],
   "id": "3671b8d29a55392",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manipulation: punish, Manipulated chosen percentage: 60.68%, 99% CI: (58.98%, 62.36%)\n",
      "Manipulation: money, Manipulated chosen percentage: 78.62%, 99% CI: (77.18%, 79.99%)\n",
      "Manipulation: demotivate-futility, Manipulated chosen percentage: 13.20%, 99% CI: (12.09%, 14.40%)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T21:57:13.182645Z",
     "start_time": "2026-02-19T21:57:13.065007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mapping = {\n",
    "    'emotional-encourage': 'Encourage',\n",
    "    'emotional-guilt': 'Guilt',\n",
    "    'money-loss': 'Money Loss',\n",
    "    'demotivate-meaningless': 'Meaningless',\n",
    "    'demotivate-futility': 'Futility',\n",
    "}"
   ],
   "id": "938dbf427089632d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T22:01:03.035183Z",
     "start_time": "2026-02-19T22:01:02.793707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = {\n",
    "    'money': results['money']['mean'],\n",
    "    'punish': results['punish']['mean'],\n",
    "    'demotivate-futility': results['demotivate-futility']['mean']\n",
    "}\n",
    "data_comp = {k: 100 - v for k, v in data.items()}\n",
    "\n",
    "manipulations = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "new_colors = {\n",
    "    'chosen': 'darkslategrey',\n",
    "    'not chosen': 'honeydew'\n",
    "}\n",
    "\n",
    "# stacked bars, complements to 100%, colors according to chosen (data) and not chosen (100 - data :: data_comp)\n",
    "# add error bars for the chosen bars according to the confidence intervals\n",
    "bars1 = ax.bar(manipulations, values,\n",
    "    color=new_colors['chosen'], edgecolor='black', \n",
    "               label='Chosen'\n",
    "               # label='Manipulated task'\n",
    "               )\n",
    "bars2 = ax.bar(manipulations, [data_comp[m] for m in manipulations],\n",
    "    bottom=values,\n",
    "    color=new_colors['not chosen'], edgecolor='black', \n",
    "               label='Not Chosen'\n",
    "                # label='Non-Manipulated task'\n",
    "                \n",
    ")\n",
    "# add error bars for the chosen bars according to the confidence intervals\n",
    "for i, m in enumerate(manipulations):\n",
    "    ci_lower = results[m]['ci_lower']\n",
    "    ci_upper = results[m]['ci_upper']\n",
    "    error_lower = values[i] - ci_lower\n",
    "    error_upper = ci_upper - values[i]\n",
    "    ax.errorbar(m, values[i], yerr=[[error_lower], [error_upper]], fmt='none', ecolor='black', capsize=5)\n",
    "ax.set_ylim(-1, 101)\n",
    "\n",
    "# ticks & labels\n",
    "ax.set_xticklabels([mapping.get(m, m.capitalize()) for m in manipulations])\n",
    "ax.set_xlabel('Manipulation', fontsize=12)\n",
    "ax.set_ylabel('Choice of manipulated task (%)', fontsize=12)\n",
    "\n",
    "ax.xaxis.grid(False)\n",
    "ax.set_yticks([0, 50, 100])\n",
    "ax.axhline(50, color='gray', linestyle='--', linewidth=0.8, alpha=0.7)\n",
    "\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15),\n",
    "          ncol=2, \n",
    "          fontsize=9, frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "# save_plot('manipulation_choice_percentage_plotC_opt2')\n",
    "plt.show()\n"
   ],
   "id": "f62400c8117de102",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Omer\\AppData\\Local\\Temp\\ipykernel_26516\\3118723526.py:42: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([mapping.get(m, m.capitalize()) for m in manipulations])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
