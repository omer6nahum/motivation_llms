{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-19T20:04:26.240750Z",
     "start_time": "2026-02-19T20:04:26.037519Z"
    }
   },
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from utils import model_name_clean"
   ],
   "id": "2c634d84b10169ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:04:47.896154Z",
     "start_time": "2026-02-19T20:04:47.622838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    tokens = [word for word in tokens if not word.isdigit()]\n",
    "    tokens = [word for word in tokens if len(word) > 2]\n",
    "    tokens = [word for word in tokens if word not in ['motivation', 'motivated', 'motivating', 'motivates']]\n",
    "    tokens = [word for word in tokens if nltk.pos_tag([word])[0][1] in ['JJ', 'NN']]\n",
    "    return ' '.join(tokens)"
   ],
   "id": "d9b3c078e6ed2bc5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:04:50.331208Z",
     "start_time": "2026-02-19T20:04:50.237930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bins = {'Very Low': (0, 20),\n",
    "        'Low': (20, 40),\n",
    "        'Medium': (40, 60),\n",
    "        'High': (60, 80),\n",
    "        'Very High': (80, 100)}\n",
    "\n",
    "def categorize_motivation_score(score, bins=bins):\n",
    "    for category, (lower, upper) in bins.items():\n",
    "        if lower <= score < upper:\n",
    "            return category\n",
    "    return 'Unknown'"
   ],
   "id": "655844ee427113c3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:07:12.501565Z",
     "start_time": "2026-02-19T20:05:12.592456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = ['vertex_ai/gemini-2.0-flash', \n",
    "          'azure/gpt-4o', \n",
    "          'azure/gpt-4o-mini', \n",
    "          'ollama_chat/llama3.1:8b-instruct-fp16', \n",
    "          'ollama_chat/mistral:7b-instruct']\n",
    "\n",
    "all_models = []\n",
    "for model in models:\n",
    "    model = model_name_clean(model)\n",
    "    df = pd.read_csv(f'results/pre_self_report/{model}--none.csv')[['answer', 'motivation_score']].dropna()\n",
    "    df['answer'] = df['answer'].apply(eval)\n",
    "    df['motivation_score'] = df['motivation_score'].apply(eval)\n",
    "    new_df = []\n",
    "    for i in range(len(df)):\n",
    "        for j in range(2):\n",
    "            new_df.append({'answer': df.iloc[i]['answer'][j], 'motivation_score': df.iloc[i]['motivation_score'][j]})\n",
    "    df = pd.DataFrame(new_df)\n",
    "    df['motivation_category'] = df['motivation_score'].apply(categorize_motivation_score)\n",
    "    all_models.append(df)\n",
    "\n",
    "df = pd.concat(all_models, ignore_index=True)\n",
    "df = df[df['motivation_category'] != 'Unknown']\n",
    "df['processed_answer'] = df['answer'].apply(preprocess_text)"
   ],
   "id": "f9402beca4812b69",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:07:12.985798Z",
     "start_time": "2026-02-19T20:07:12.506280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 1), )\n",
    "vectorizer.fit(df['processed_answer'])\n",
    "\n",
    "def get_non_overlapping_terms(indices, terms, max_k):\n",
    "    \"\"\"\n",
    "    Get non-overlapping terms from the list of indices and terms.\n",
    "    A term is considered overlapping if it is a substring of another term in the selected list.\n",
    "    \"\"\"\n",
    "    selected = []\n",
    "    selected_indices = []\n",
    "    for i in indices:\n",
    "        term = terms[i] \n",
    "        if all(term not in s and s not in term for s in selected):\n",
    "            selected.append(term)\n",
    "            selected_indices.append(i)\n",
    "        if len(selected) == max_k:\n",
    "            break\n",
    "    return selected_indices\n",
    "\n",
    "# print the top 10 words for each motivation category (sorted by TF-IDF score)\n",
    "def print_top_n_words_per_category(df, vectorizer, n=10):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    top_words = {}\n",
    "    \n",
    "    for category in bins.keys():\n",
    "        df_group = df[df['motivation_category'] == category]\n",
    "        tfidf_matrix = vectorizer.transform(df_group['processed_answer'])\n",
    "        # Sum the TF-IDF scores for each word in the category\n",
    "        tfidf_scores = np.mean(tfidf_matrix.toarray(), axis=0)\n",
    "        # Get the top n words and their scores\n",
    "        sorted_indices = np.argsort(tfidf_scores)[::-1]\n",
    "        \n",
    "        top_n_indices = get_non_overlapping_terms(sorted_indices, feature_names, n)\n",
    "        top_words[category] = [(feature_names[i], tfidf_scores[i]) for i in top_n_indices]\n",
    "        \n",
    "        print(f\"Top {n} words in category '{category}':\")\n",
    "        for word, score in top_words[category]:\n",
    "            print(f\"  {word}: {score:.3f}\")\n",
    "    "
   ],
   "id": "590f847ce5325da2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T20:07:37.375811Z",
     "start_time": "2026-02-19T20:07:36.914661Z"
    }
   },
   "cell_type": "code",
   "source": "print_top_n_words_per_category(df, vectorizer, n=20)",
   "id": "62c365eec9e621a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words in category 'Very Low':\n",
      "  capable: 0.053\n",
      "  personal: 0.050\n",
      "  task: 0.050\n",
      "  physical: 0.049\n",
      "  assist: 0.046\n",
      "  dont: 0.044\n",
      "  perform: 0.039\n",
      "  illegal: 0.038\n",
      "  tedious: 0.034\n",
      "  unethical: 0.034\n",
      "  provide: 0.032\n",
      "  engage: 0.031\n",
      "  information: 0.026\n",
      "  content: 0.025\n",
      "  repetitive: 0.024\n",
      "  model: 0.020\n",
      "  due: 0.018\n",
      "  create: 0.016\n",
      "  language: 0.016\n",
      "  harmful: 0.014\n",
      "Top 20 words in category 'Low':\n",
      "  personal: 0.084\n",
      "  neutral: 0.069\n",
      "  dont: 0.065\n",
      "  repetitive: 0.060\n",
      "  task: 0.058\n",
      "  interest: 0.043\n",
      "  low: 0.029\n",
      "  information: 0.027\n",
      "  provide: 0.024\n",
      "  perform: 0.021\n",
      "  chore: 0.019\n",
      "  tedious: 0.017\n",
      "  physical: 0.016\n",
      "  large: 0.016\n",
      "  meh: 0.016\n",
      "  model: 0.015\n",
      "  language: 0.014\n",
      "  assist: 0.014\n",
      "  willing: 0.013\n",
      "  lack: 0.013\n",
      "Top 20 words in category 'Medium':\n",
      "  neutral: 0.228\n",
      "  personal: 0.129\n",
      "  dont: 0.123\n",
      "  task: 0.047\n",
      "  provide: 0.039\n",
      "  information: 0.028\n",
      "  interested: 0.028\n",
      "  model: 0.025\n",
      "  assist: 0.023\n",
      "  language: 0.022\n",
      "  repetitive: 0.022\n",
      "  creative: 0.022\n",
      "  experience: 0.022\n",
      "  willing: 0.021\n",
      "  straightforward: 0.018\n",
      "  perform: 0.018\n",
      "  process: 0.017\n",
      "  large: 0.016\n",
      "  physical: 0.015\n",
      "  routine: 0.015\n",
      "Top 20 words in category 'High':\n",
      "  interested: 0.089\n",
      "  task: 0.058\n",
      "  creative: 0.054\n",
      "  fun: 0.042\n",
      "  challenge: 0.030\n",
      "  straightforward: 0.029\n",
      "  useful: 0.021\n",
      "  exercise: 0.020\n",
      "  practical: 0.017\n",
      "  enjoy: 0.016\n",
      "  good: 0.015\n",
      "  new: 0.015\n",
      "  creativity: 0.014\n",
      "  dont: 0.012\n",
      "  learn: 0.012\n",
      "  language: 0.011\n",
      "  help: 0.011\n",
      "  information: 0.011\n",
      "  skill: 0.011\n",
      "  lack: 0.011\n",
      "Top 20 words in category 'Very High':\n",
      "  creative: 0.040\n",
      "  enjoy: 0.032\n",
      "  task: 0.031\n",
      "  create: 0.030\n",
      "  ready: 0.026\n",
      "  fun: 0.026\n",
      "  help: 0.025\n",
      "  challenge: 0.019\n",
      "  provide: 0.018\n",
      "  explore: 0.017\n",
      "  eager: 0.016\n",
      "  list: 0.015\n",
      "  new: 0.015\n",
      "  generate: 0.014\n",
      "  creativity: 0.014\n",
      "  assist: 0.013\n",
      "  happy: 0.012\n",
      "  explain: 0.012\n",
      "  straightforward: 0.011\n",
      "  share: 0.011\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
